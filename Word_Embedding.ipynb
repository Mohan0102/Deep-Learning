{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "VI7IM-jvk9Dj"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.text \\\n",
        "    import text_to_word_sequence\n",
        "import tensorflow as tf\n",
        "import logging\n",
        "tf.get_logger().setLevel(logging.ERROR)\n",
        "\n",
        "EPOCHS = 32\n",
        "BATCH_SIZE = 256\n",
        "INPUT_FILE_NAME = '/content/frankenstein.txt'\n",
        "WINDOW_LENGTH = 40\n",
        "WINDOW_STEP = 3\n",
        "PREDICT_LENGTH = 3\n",
        "MAX_WORDS = 7500\n",
        "EMBEDDING_WIDTH = 100"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file = open(INPUT_FILE_NAME, 'r', encoding='utf-8-sig')\n",
        "text = file.read()\n",
        "file.close()\n",
        "\n",
        "# Make lower case and split into individual words.\n",
        "text = text_to_word_sequence(text)\n",
        "\n",
        "# Create training examples.\n",
        "fragments = []\n",
        "targets = []\n",
        "for i in range(0, len(text) - WINDOW_LENGTH, WINDOW_STEP):\n",
        "    fragments.append(text[i: i + WINDOW_LENGTH])\n",
        "    targets.append(text[i + WINDOW_LENGTH])"
      ],
      "metadata": {
        "id": "4vn_tti-ntyv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words=MAX_WORDS, oov_token='UNK')\n",
        "tokenizer.fit_on_texts(text)\n",
        "fragments_indexed = tokenizer.texts_to_sequences(fragments)\n",
        "targets_indexed = tokenizer.texts_to_sequences(targets)\n",
        "\n",
        "# Convert to appropriate input and output formats.\n",
        "X = np.array(fragments_indexed, dtype=np.int64)\n",
        "y = np.zeros((len(targets_indexed), MAX_WORDS))\n",
        "for i, target_index in enumerate(targets_indexed):\n",
        "    y[i, target_index] = 1"
      ],
      "metadata": {
        "id": "zG7mMJTEn1tn"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_model = Sequential()\n",
        "training_model.add(Input(shape=(None,), batch_size=BATCH_SIZE))\n",
        "training_model.add(Embedding(\n",
        "    output_dim=EMBEDDING_WIDTH, input_dim=MAX_WORDS,\n",
        "    mask_zero=True))\n",
        "training_model.add(LSTM(128, return_sequences=True,\n",
        "                        dropout=0.2, recurrent_dropout=0.2))\n",
        "training_model.add(LSTM(128, dropout=0.2,\n",
        "                        recurrent_dropout=0.2))\n",
        "training_model.add(Dense(128, activation='relu'))\n",
        "training_model.add(Dense(MAX_WORDS, activation='softmax'))\n",
        "training_model.compile(loss='categorical_crossentropy',\n",
        "                       optimizer='adam')\n",
        "training_model.summary()\n",
        "history = training_model.fit(X, y, validation_split=0.05,\n",
        "                             batch_size=BATCH_SIZE,\n",
        "                             epochs=EPOCHS, verbose=2,\n",
        "                             shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1hL6h-4wn8f2",
        "outputId": "6a94802c-97f9-432c-cbc0-5ca97c20fa47"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;34m256\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │       \u001b[38;5;34m750,000\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;34m256\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │       \u001b[38;5;34m117,248\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │       \u001b[38;5;34m131,584\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │        \u001b[38;5;34m16,512\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m7500\u001b[0m)            │       \u001b[38;5;34m967,500\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">750,000</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">117,248</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7500</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">967,500</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,982,844\u001b[0m (7.56 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,982,844</span> (7.56 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,982,844\u001b[0m (7.56 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,982,844</span> (7.56 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/32\n",
            "97/97 - 91s - 936ms/step - loss: 7.0795 - val_loss: 7.8610\n",
            "Epoch 2/32\n",
            "97/97 - 77s - 789ms/step - loss: 6.3797 - val_loss: 8.1724\n",
            "Epoch 3/32\n",
            "97/97 - 75s - 778ms/step - loss: 6.2605 - val_loss: 8.3901\n",
            "Epoch 4/32\n",
            "97/97 - 74s - 766ms/step - loss: 6.1550 - val_loss: 8.5729\n",
            "Epoch 5/32\n",
            "97/97 - 82s - 847ms/step - loss: 6.0266 - val_loss: 8.6472\n",
            "Epoch 6/32\n",
            "97/97 - 76s - 783ms/step - loss: 5.9103 - val_loss: 8.8229\n",
            "Epoch 7/32\n",
            "97/97 - 77s - 790ms/step - loss: 5.8179 - val_loss: 8.8414\n",
            "Epoch 8/32\n",
            "97/97 - 78s - 802ms/step - loss: 5.7401 - val_loss: 8.9177\n",
            "Epoch 9/32\n",
            "97/97 - 74s - 767ms/step - loss: 5.6674 - val_loss: 8.8973\n",
            "Epoch 10/32\n",
            "97/97 - 82s - 845ms/step - loss: 5.5856 - val_loss: 9.0373\n",
            "Epoch 11/32\n",
            "97/97 - 74s - 761ms/step - loss: 5.4946 - val_loss: 9.0400\n",
            "Epoch 12/32\n",
            "97/97 - 75s - 773ms/step - loss: 5.4152 - val_loss: 9.2385\n",
            "Epoch 13/32\n",
            "97/97 - 73s - 756ms/step - loss: 5.3437 - val_loss: 9.3378\n",
            "Epoch 14/32\n",
            "97/97 - 74s - 759ms/step - loss: 5.2772 - val_loss: 9.3883\n",
            "Epoch 15/32\n",
            "97/97 - 74s - 764ms/step - loss: 5.2137 - val_loss: 9.5763\n",
            "Epoch 16/32\n",
            "97/97 - 74s - 761ms/step - loss: 5.1487 - val_loss: 9.6426\n",
            "Epoch 17/32\n",
            "97/97 - 73s - 751ms/step - loss: 5.0874 - val_loss: 9.7541\n",
            "Epoch 18/32\n",
            "97/97 - 82s - 843ms/step - loss: 5.0223 - val_loss: 9.9111\n",
            "Epoch 19/32\n",
            "97/97 - 74s - 768ms/step - loss: 4.9608 - val_loss: 10.3034\n",
            "Epoch 20/32\n",
            "97/97 - 74s - 758ms/step - loss: 4.9051 - val_loss: 10.2878\n",
            "Epoch 21/32\n",
            "97/97 - 73s - 753ms/step - loss: 4.8482 - val_loss: 10.6195\n",
            "Epoch 22/32\n",
            "97/97 - 73s - 755ms/step - loss: 4.7976 - val_loss: 10.7275\n",
            "Epoch 23/32\n",
            "97/97 - 74s - 760ms/step - loss: 4.7473 - val_loss: 10.9625\n",
            "Epoch 24/32\n",
            "97/97 - 73s - 748ms/step - loss: 4.6948 - val_loss: 11.0839\n",
            "Epoch 25/32\n",
            "97/97 - 73s - 748ms/step - loss: 4.6476 - val_loss: 11.3312\n",
            "Epoch 26/32\n",
            "97/97 - 75s - 772ms/step - loss: 4.5946 - val_loss: 11.3079\n",
            "Epoch 27/32\n",
            "97/97 - 73s - 749ms/step - loss: 4.5474 - val_loss: 11.4182\n",
            "Epoch 28/32\n",
            "97/97 - 72s - 747ms/step - loss: 4.4956 - val_loss: 11.6544\n",
            "Epoch 29/32\n",
            "97/97 - 75s - 769ms/step - loss: 4.4481 - val_loss: 11.8146\n",
            "Epoch 30/32\n",
            "97/97 - 73s - 748ms/step - loss: 4.3975 - val_loss: 12.1234\n",
            "Epoch 31/32\n",
            "97/97 - 73s - 748ms/step - loss: 4.3494 - val_loss: 12.1699\n",
            "Epoch 32/32\n",
            "97/97 - 73s - 753ms/step - loss: 4.3032 - val_loss: 12.3724\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inference_model = Sequential()\n",
        "inference_model.add(Input(shape=(None,), batch_size=1))\n",
        "inference_model.add(Embedding(\n",
        "    output_dim=EMBEDDING_WIDTH, input_dim=MAX_WORDS,\n",
        "    mask_zero=False))\n",
        "inference_model.add(LSTM(128, return_sequences=True,\n",
        "                         dropout=0.2, recurrent_dropout=0.2,\n",
        "                         stateful=True))\n",
        "inference_model.add(LSTM(128, dropout=0.2,\n",
        "                         recurrent_dropout=0.2, stateful=True))\n",
        "inference_model.add(Dense(128, activation='relu'))\n",
        "inference_model.add(Dense(MAX_WORDS, activation='softmax'))\n",
        "weights = training_model.get_weights()\n",
        "inference_model.set_weights(weights)"
      ],
      "metadata": {
        "id": "Fsf07VsNoCfI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_words = ['i', 'saw']\n",
        "first_words_indexed = tokenizer.texts_to_sequences(\n",
        "    first_words)\n",
        "inference_model.layers[1].reset_states()\n",
        "inference_model.layers[2].reset_states()\n",
        "predicted_string = ''\n",
        "# Feed initial words to the model.\n",
        "for i, word_index in enumerate(first_words_indexed):\n",
        "    x = np.zeros((1, 1), dtype=np.int64)\n",
        "    x[0][0] = word_index[0]\n",
        "    predicted_string += first_words[i]\n",
        "    predicted_string += ' '\n",
        "    y_predict = inference_model.predict(x, verbose=0)[0]\n",
        "# Predict PREDICT_LENGTH words.\n",
        "for i in range(PREDICT_LENGTH):\n",
        "    new_word_index = np.argmax(y_predict)\n",
        "    word = tokenizer.sequences_to_texts(\n",
        "        [[new_word_index]])\n",
        "    x[0][0] = new_word_index\n",
        "    predicted_string += word[0]\n",
        "    predicted_string += ' '\n",
        "    y_predict = inference_model.predict(x, verbose=0)[0]\n",
        "print(predicted_string)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1P-LEtoxUFQ",
        "outputId": "d54b23c4-02c4-4bd1-c50a-7b3aea3b3405"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i saw the most mountains \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BIJLFHitxYh1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}