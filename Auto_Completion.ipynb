{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "zmVTQKNOPdCP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Input\n",
        "import tensorflow as tf\n",
        "import logging\n",
        "tf.get_logger().setLevel(logging.ERROR)\n",
        "\n",
        "EPOCHS = 32\n",
        "BATCH_SIZE = 256\n",
        "INPUT_FILE_NAME = '/content/frankenstein.txt'\n",
        "WINDOW_LENGTH = 40\n",
        "WINDOW_STEP = 3\n",
        "BEAM_SIZE = 8\n",
        "NUM_LETTERS = 11\n",
        "MAX_LENGTH = 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "3o-oCuuF7U4Q"
      },
      "outputs": [],
      "source": [
        "file = open(INPUT_FILE_NAME, 'r', encoding='utf-8-sig')\n",
        "text = file.read()\n",
        "file.close()\n",
        "\n",
        "# Make lowercase and remove newline and extra spaces.\n",
        "text = text.lower()\n",
        "text = text.replace('\\n', ' ')\n",
        "text = text.replace('  ', ' ')\n",
        "\n",
        "# Encode characters as indices.\n",
        "unique_chars = list(set(text))\n",
        "char_to_index = dict((ch, index) for index,\n",
        "                     ch in enumerate(unique_chars))\n",
        "index_to_char = dict((index, ch) for index,\n",
        "                     ch in enumerate(unique_chars))\n",
        "encoding_width = len(char_to_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "hAMu7Att1TXG"
      },
      "outputs": [],
      "source": [
        "fragments = []\n",
        "targets = []\n",
        "for i in range(0, len(text) - WINDOW_LENGTH, WINDOW_STEP):\n",
        "    fragments.append(text[i: i + WINDOW_LENGTH])\n",
        "    targets.append(text[i + WINDOW_LENGTH])\n",
        "\n",
        "# Convert to one-hot encoded training data.\n",
        "X = np.zeros((len(fragments), WINDOW_LENGTH, encoding_width))\n",
        "y = np.zeros((len(fragments), encoding_width))\n",
        "for i, fragment in enumerate(fragments):\n",
        "    for j, char in enumerate(fragment):\n",
        "        X[i, j, char_to_index[char]] = 1\n",
        "    target_char = targets[i]\n",
        "    y[i, char_to_index[target_char]] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CfZIBMgB1ZbB",
        "outputId": "3794b6dd-9656-46db-92e1-9e81a4f0ff00"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">95,232</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">57</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,353</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;34m256\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │        \u001b[38;5;34m95,232\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)             │       \u001b[38;5;34m131,584\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m57\u001b[0m)              │         \u001b[38;5;34m7,353\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">234,169</span> (914.72 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m234,169\u001b[0m (914.72 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">234,169</span> (914.72 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m234,169\u001b[0m (914.72 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/32\n",
            "542/542 - 234s - 431ms/step - loss: 2.7784 - val_loss: 2.6887\n",
            "Epoch 2/32\n",
            "542/542 - 228s - 421ms/step - loss: 2.4591 - val_loss: 2.5733\n",
            "Epoch 3/32\n",
            "542/542 - 229s - 423ms/step - loss: 2.3499 - val_loss: 2.4938\n",
            "Epoch 4/32\n",
            "542/542 - 263s - 485ms/step - loss: 2.2739 - val_loss: 2.4138\n",
            "Epoch 5/32\n",
            "542/542 - 233s - 429ms/step - loss: 2.2203 - val_loss: 2.3730\n",
            "Epoch 6/32\n",
            "542/542 - 235s - 434ms/step - loss: 2.1798 - val_loss: 2.3422\n",
            "Epoch 7/32\n",
            "542/542 - 232s - 427ms/step - loss: 2.1463 - val_loss: 2.3201\n",
            "Epoch 8/32\n",
            "542/542 - 235s - 434ms/step - loss: 2.1154 - val_loss: 2.3007\n",
            "Epoch 9/32\n",
            "542/542 - 230s - 424ms/step - loss: 2.0929 - val_loss: 2.2863\n",
            "Epoch 10/32\n",
            "542/542 - 260s - 480ms/step - loss: 2.0632 - val_loss: 2.2621\n",
            "Epoch 11/32\n",
            "542/542 - 266s - 491ms/step - loss: 2.0447 - val_loss: 2.2749\n",
            "Epoch 12/32\n",
            "542/542 - 234s - 432ms/step - loss: 2.0194 - val_loss: 2.2459\n",
            "Epoch 13/32\n",
            "542/542 - 261s - 482ms/step - loss: 2.0005 - val_loss: 2.2240\n",
            "Epoch 14/32\n",
            "542/542 - 232s - 427ms/step - loss: 1.9853 - val_loss: 2.2371\n",
            "Epoch 15/32\n",
            "542/542 - 231s - 426ms/step - loss: 1.9683 - val_loss: 2.2089\n",
            "Epoch 16/32\n",
            "542/542 - 229s - 422ms/step - loss: 1.9548 - val_loss: 2.2018\n",
            "Epoch 17/32\n",
            "542/542 - 230s - 425ms/step - loss: 1.9379 - val_loss: 2.1957\n",
            "Epoch 18/32\n",
            "542/542 - 232s - 428ms/step - loss: 1.9247 - val_loss: 2.2083\n",
            "Epoch 19/32\n",
            "542/542 - 229s - 423ms/step - loss: 1.9158 - val_loss: 2.1846\n",
            "Epoch 20/32\n",
            "542/542 - 262s - 484ms/step - loss: 1.9016 - val_loss: 2.1711\n",
            "Epoch 21/32\n",
            "542/542 - 234s - 431ms/step - loss: 1.8904 - val_loss: 2.1705\n",
            "Epoch 22/32\n",
            "542/542 - 255s - 471ms/step - loss: 1.8790 - val_loss: 2.1733\n",
            "Epoch 23/32\n",
            "542/542 - 265s - 488ms/step - loss: 1.8681 - val_loss: 2.1554\n",
            "Epoch 24/32\n",
            "542/542 - 230s - 424ms/step - loss: 1.8557 - val_loss: 2.1717\n",
            "Epoch 25/32\n",
            "542/542 - 230s - 425ms/step - loss: 1.8445 - val_loss: 2.1532\n",
            "Epoch 26/32\n",
            "542/542 - 228s - 420ms/step - loss: 1.8427 - val_loss: 2.1626\n",
            "Epoch 27/32\n",
            "542/542 - 228s - 421ms/step - loss: 1.8327 - val_loss: 2.1505\n",
            "Epoch 28/32\n",
            "542/542 - 234s - 431ms/step - loss: 1.8232 - val_loss: 2.1402\n",
            "Epoch 29/32\n",
            "542/542 - 259s - 478ms/step - loss: 1.8144 - val_loss: 2.1401\n",
            "Epoch 30/32\n",
            "542/542 - 260s - 479ms/step - loss: 1.8056 - val_loss: 2.1310\n",
            "Epoch 31/32\n",
            "542/542 - 258s - 477ms/step - loss: 1.8010 - val_loss: 2.1155\n",
            "Epoch 32/32\n",
            "542/542 - 263s - 485ms/step - loss: 1.7917 - val_loss: 2.1233\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Input(shape=(None, encoding_width), batch_size=BATCH_SIZE))\n",
        "model.add(LSTM(128, return_sequences=True, dropout=0.2))\n",
        "model.add(LSTM(128, dropout=0.2))\n",
        "model.add(Dense(encoding_width, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam')\n",
        "model.summary()\n",
        "history = model.fit(X, y, validation_split=0.05,\n",
        "                    batch_size=BATCH_SIZE,\n",
        "                    epochs=EPOCHS, verbose=2,\n",
        "                    shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "mJv8rXtV1dfI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "928735a6-c3fe-47c9-ecf1-c528cb9ae8d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the body of the most\n",
            "the body of the ligh\n",
            "the body of the pres\n",
            "the body of the morn\n",
            "the body of the mont\n",
            "the body of the more\n",
            "the body of the pros\n",
            "the body of the mort\n"
          ]
        }
      ],
      "source": [
        "letters = 'the body '\n",
        "one_hots = []\n",
        "for i, char in enumerate(letters):\n",
        "    x = np.zeros(encoding_width)\n",
        "    x[char_to_index[char]] = 1\n",
        "    one_hots.append(x)\n",
        "beams = [(np.log(1.0), letters, one_hots)]\n",
        "\n",
        "# Predict NUM_LETTERS into the future.\n",
        "for i in range(NUM_LETTERS):\n",
        "    minibatch_list = []\n",
        "    # Create minibatch from one-hot encodings, and predict.\n",
        "    for triple in beams:\n",
        "        minibatch_list.append(triple[2])\n",
        "    minibatch = np.array(minibatch_list)\n",
        "    y_predict = model.predict(minibatch, verbose=0)\n",
        "    new_beams = []\n",
        "    for j, softmax_vec in enumerate(y_predict):\n",
        "        triple = beams[j]\n",
        "        # Create BEAM_SIZE new beams from each existing beam.\n",
        "        for k in range(BEAM_SIZE):\n",
        "            char_index = np.argmax(softmax_vec)\n",
        "            new_prob = triple[0] + np.log(\n",
        "                softmax_vec[char_index])\n",
        "            new_letters = triple[1] + index_to_char[char_index]\n",
        "            x = np.zeros(encoding_width)\n",
        "            x[char_index] = 1\n",
        "            new_one_hots = triple[2].copy()\n",
        "            new_one_hots.append(x)\n",
        "            new_beams.append((new_prob, new_letters,\n",
        "                              new_one_hots))\n",
        "            softmax_vec[char_index] = 0\n",
        "    # Prune tree to only keep BEAM_SIZE most probable beams.\n",
        "    new_beams.sort(key=lambda tup: tup[0], reverse=True)\n",
        "    beams = new_beams[0:BEAM_SIZE]\n",
        "for item in beams:\n",
        "    print(item[1])"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0mO_qIYWHKPl"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}